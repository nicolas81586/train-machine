# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13_2Gv0pS_NI1n7P8ovBRm-en9iyIrGI7

Importar bibliotecas
"""

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from yellowbrick.regressor import ResidualsPlot
import seaborn as sns
from sklearn.metrics import roc_curve

# Carregar base de dados Iris

iris = load_iris()
df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['target'] = iris.target

print(df.describe())

print(df['target'].value_counts())

sns.pairplot(df, hue='target')
plt.show()

# Histograma dos atributos
df.hist(figsize=(10,6))
plt.show()

#Box Plot
features = list(df.select_dtypes(include=['float']).columns) # isola os atributos pelo tipo de dados
fig, ax = plt.subplots(len(features), 1, figsize=(4, 6))
for i in range(len(features)):
    sns.boxplot(ax=ax[i], x=features[i], data=df)
fig.tight_layout(pad=1)
plt.show()

# Heatmap para entender as relações entre diferentes recursos numéricos
correlation_matrix = df.select_dtypes(exclude=['object']).corr() # exclui variáveis-alvo
sns.heatmap(correlation_matrix, cmap = 'RdYlBu', annot=True, fmt=".2f", square=True, linewidths=.5)
plt.show()

"""Dividir base em treinamento e teste"""

X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.3, random_state=16)

"""Modelos de machine learning"""

modelos = {
    'Regressão Logística': LogisticRegression(max_iter=1000),
    'Árvore de Decisão': DecisionTreeClassifier(),
    'Floresta Aleatória': RandomForestClassifier(),
    #'Regressão Linear': LinearRegression()
}

"""Treinar e avaliar modelos"""

relatorio = []
for nome, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    precisao = accuracy_score(y_test, y_pred)
    relatorio.append((nome, precisao, classification_report(y_test, y_pred)))

"""Imprimir relatório"""

print("Relatório de Modelos de Machine Learning")
print("----------------------------------------")
for nome, precisao, report in relatorio:
    print(f"Modelo: {nome}")
    print(f"Precisão: {precisao:.2f}")
    print(report)
    print()

relatorio = []
for nome, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    precisao = accuracy_score(y_test, y_pred)
    taxa_erro = 1 - precisao
    num_parametros = modelo.get_params().__len__()
    auc = roc_auc_score(y_test, modelo.predict_proba(X_test), multi_class='ovo')
    relatorio.append((nome, precisao, taxa_erro, num_parametros,auc))

# Criar tabela
tabela = pd.DataFrame(relatorio, columns=['Modelo', 'Precisão', 'Taxa Erro', 'N. Parâmetros','auc'])

# Imprimir tabela
print(tabela)

for nome, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred_proba = modelo.predict_proba(X_test)

    # Escolher uma classe como positiva (por exemplo, classe 1)
    pos_label = 1

    # Cálculo da curva ROC para a classe positiva
    fpr, tpr, _ = roc_curve((y_test == pos_label).astype(int), y_pred_proba[:, pos_label])

    # Plot da curva ROC
    plt.plot(fpr, tpr, label=f"{nome} - Classe {pos_label}")

plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.title('Curva ROC')
plt.legend()
plt.show()